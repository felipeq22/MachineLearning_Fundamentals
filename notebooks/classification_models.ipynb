{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 2 - Juan Quinones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select one: Assume we have a large labeled dataset that is randomly divided into a training set and a test set, and we would like to classify points in the test set using a kNN classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. (1 point) In order to minimize the classification error on this test set, we should always choose the value of k which minimizes the training set error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2 points) Select one: Instead of choosing the hyperparameters by merely minimizing the\n",
    "training set error, we instead consider splitting the training-all data set into a training and a validation data set, and choose the hyperparameters that lead to lower validation error. Is choosing hyperparameters based on validation error better than choosing hyper-parameters based on training error?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yes, lowering validation error instead of training error is better because lowering training error will not help generalize our model and may lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. (3 points) Select all that apply: Which of the following is/are correct statement(s) about kNN models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A larger k tends to give a smoother decision boundary.\n",
    "- To reduce the impact of noise or outliers in our data, we should increase the value k.\n",
    "- We can use cross-validation to help us select the value of k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consider a k nearest neighbors (kNN) binary classifier which assigns the class of a test point to be the class of the majority of the k nearest neighbors, according to the Euclidean distance metric. Assume that ties are broken by selecting one of the labels uniformly at random.\n",
    "\n",
    "i. (2 points) Using fig. 1 to train the classifier and choosing k = 6, what is the training error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'x': []}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
