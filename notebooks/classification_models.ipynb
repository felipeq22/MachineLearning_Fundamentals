{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 2 - Juan Quinones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select one: Assume we have a large labeled dataset that is randomly divided into a training set and a test set, and we would like to classify points in the test set using a kNN classifier.\n",
    "\n",
    "i. (1 point) In order to minimize the classification error on this test set, we should always choose the value of k which minimizes the training set error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2 points) Select one: Instead of choosing the hyperparameters by merely minimizing the\n",
    "training set error, we instead consider splitting the training-all data set into a training and a validation data set, and choose the hyperparameters that lead to lower validation error. Is choosing hyperparameters based on validation error better than choosing hyper-parameters based on training error?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: Yes, lowering validation error instead of training error is better because lowering training error will not help generalize our model and may lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. (3 points) Select all that apply: Which of the following is/are correct statement(s) about kNN models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "- A larger k tends to give a smoother decision boundary.\n",
    "- To reduce the impact of noise or outliers in our data, we should increase the value k.\n",
    "- We can use cross-validation to help us select the value of k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consider a k nearest neighbors (kNN) binary classifier which assigns the class of a test point to be the class of the majority of the k nearest neighbors, according to the Euclidean distance metric. Assume that ties are broken by selecting one of the labels uniformly at random.\n",
    "\n",
    "i. (2 points) Using fig. 1 to train the classifier and choosing k = 6, what is the training error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error Rate: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = {'x': [1,2,2,3,3,4,5,5,6,7,7,8,8,9], \n",
    "        'y': [5,6,7,7,8,8,9,1,2,2,3,3,4,5],\n",
    "        't': [0,0,1,0,1,0,0,1,1,0,1,0,1,1]}\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "X_train = data[['x', 'y']]\n",
    "y_train = data['t']\n",
    "\n",
    "k = 6\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "train_error_rate = 1 - accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Error Rate:\", train_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. (2 points) Select all that apply: Let’s say that we have a new test point (not present in our training data) xnew = [3, 9]T that we would like to apply our kNN classifier to, as seen in fig. 2.\n",
    "For which values of k is this test point correctly classified by the kNN algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k = 5 the prediction was correct\n",
      "for k = 9 the prediction was correct\n",
      "for k = 12 the prediction was correct\n"
     ]
    }
   ],
   "source": [
    "x_new = {'x': [3], 'y':[9]}\n",
    "x_new = pd.DataFrame(x_new)\n",
    "y_new = 0\n",
    "\n",
    "k_list = [1,5,9,12]\n",
    "\n",
    "for k in k_list:\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = knn.predict(x_new)\n",
    "\n",
    "    if y_train_pred[0] == y_new:\n",
    "        \n",
    "        print(f'for k = {k} the prediction was correct')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We would like to fit a linear regression model to the dataset\n",
    "\n",
    "i. (1 point) Select one: How many coefficients (wk) do you need to estimate? When solving for these coefficients, how many equations do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: M coefficients, N equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. (2 points) Select one: We solve for each coefficient θk (1 ≤ k ≤ M) by deriving an expression of θk from the critical point ∂L(w) = 0. What is the expression for each θk in\n",
    "∂θk\n",
    "terms of the dataset (x(1),y(1)), ···, (x(N),y(N)) and θ1,··· ,θk−1,θk+1,··· ,θM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Answer:\n",
    "\n",
    "![Example Image](photo12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. (1point) Consider a dataset D such that we fit a line y = w1x+b1. Let x ̄ and y ̄ be the mean of the x and y coordinates, respectively. After mean centering the dataset to create Dnew = \u0000(x(1) − x ̄, y(1) − y ̄), . . . , (x(n) − x ̄, y(n) − y ̄)\u0001, let the solution to linear regression on Dnew be y = w2x + b2. Explain how w2 compares to w1 and justify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER:\n",
    "\n",
    "w2 = w1. Mean centering data shifts the data and does not scale the coordinates; therefore, it does not change the fitted regression line’s slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (2 points) Select all that apply: Which of the following are true about logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our formulation of binary logistic regression will work with both continuous and binary features.\n",
    "* Binary Logistic Regression will form a linear decision boundary in our feature space, assuming no feature engineering.\n",
    "* The sigmoid function is convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (1 point) can be expressed as Select one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example Image](photo3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example Image](photo2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (2 points) Data is separable in one dimension if there exists a threshold t such that all values less than t have one class label and all values greater than or equal to t have the other class label. If you train an unregularized logistic regression model for infinite iterations on training data that is separable in at least one dimension, the corresponding weight(s) can go to infinity in magnitude. What is an explanation for this phenomenon?\n",
    "Hint: Think about what happens to the probabilities if we train an unregularized logistic regression model, and the role of the weights when calculating such probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
